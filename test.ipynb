{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbk/miniconda3/envs/anlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from typing import AnyStr\n",
    "from typing import List\n",
    "import ipdb\n",
    "import krippendorff\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "from transformers import DistilBertConfig\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from datareader import *\n",
    "\n",
    "from metrics import MultiDatasetClassificationEvaluator\n",
    "from metrics import ClassificationEvaluator\n",
    "from metrics import acc_f1\n",
    "\n",
    "\n",
    "from metrics import plot_label_distribution\n",
    "from model import MultiTransformerClassifier\n",
    "from model import VanillaBert\n",
    "from model import *\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = 'distilbert-base-uncased'\n",
    "bert_config = DistilBertConfig.from_pretrained(bert_model, num_labels=2, output_hidden_states=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert = DistilBertForSequenceClassification(bert_config)\n",
    "\n",
    "model = MultiViewTransformerNetworkAveragingIndividuals(\n",
    "            bert_model,\n",
    "            bert_config,\n",
    "            4\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.domain_experts[0].load_state_dict(torch.load('checkpoints/model_books_3.pth'))\n",
    "\n",
    "model.domain_experts[3].load_state_dict(torch.load('checkpoints/model_kitchen_&_housewares_3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(bert_model)\n",
    "all_dsets = [MultiDomainSentimentDataset(\n",
    "    'data/sentiment-dataset',\n",
    "    [domain],\n",
    "    tokenizer=tokenizer,\n",
    ") for domain in [\"books\",\"dvd\", \"electronics\", \"kitchen_&_housewares\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbk/miniconda3/envs/anlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "Evaluation: 100%|██████████| 250/250 [00:20<00:00, 12.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.9735197651386261, 0.8955, 0.8734655335221907, 0.925, 0.8984944147644488),\n",
       " [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_dset = all_dsets[0]\n",
    "book_dset.set_domain_id(0)\n",
    "evaluator = ClassificationEvaluator(book_dset, device, use_domain=True)\n",
    "out = evaluator.evaluate(model, domain=0)\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbk/miniconda3/envs/anlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "Evaluation: 100%|██████████| 250/250 [00:19<00:00, 12.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1.3882596783638002, 0.5165, 0.8367346938775511, 0.041, 0.07816968541468065),\n",
       " [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = ClassificationEvaluator(book_dset, device, use_domain=True)\n",
    "out = evaluator.evaluate(model, domain=2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/250 [00:00<?, ?it/s]/home/jbk/miniconda3/envs/anlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "Evaluation: 100%|██████████| 250/250 [00:13<00:00, 18.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7555985431671143, 0.9895, 0.9870646766169154, 0.992, 0.9895261845386534),\n",
       " [])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kitchen_dset = all_dsets[3]\n",
    "kitchen_dset.set_domain_id(3)\n",
    "evaluator = ClassificationEvaluator(kitchen_dset, device, use_domain=True)\n",
    "out = evaluator.evaluate(model, domain=0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/250 [00:00<?, ?it/s]/home/jbk/miniconda3/envs/anlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "Evaluation: 100%|██████████| 250/250 [00:15<00:00, 16.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.772923944234848, 0.98, 0.9771371769383698, 0.983, 0.9800598205383848), [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics_dset = all_dsets[2]\n",
    "electronics_dset.set_domain_id(2)\n",
    "evaluator = ClassificationEvaluator(electronics_dset, device, use_domain=False)\n",
    "out = evaluator.evaluate(model, domain=0)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/250 [00:00<?, ?it/s]/home/jbk/miniconda3/envs/anlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "Evaluation: 100%|██████████| 250/250 [00:21<00:00, 11.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7760259518623353, 0.976, 0.9779116465863453, 0.974, 0.9759519038076152),\n",
       " [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvd_dset = all_dsets[1]\n",
    "dvd_dset.set_domain_id(1)\n",
    "evaluator = ClassificationEvaluator(dvd_dset, device, use_domain=True)\n",
    "out = evaluator.evaluate(model, domain=0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
